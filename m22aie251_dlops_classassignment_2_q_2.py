# -*- coding: utf-8 -*-
"""M22AIE251_DLOps_ClassAssignment_2_Q_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EEmkmEuyS1NjSA8KEl1S-UItcs5a6hOA
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
# Version 1 

# Version 2
# Load FashionMNIST dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images to match ResNet input size
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)  # Reduce batch size

testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)  # Reduce batch size

# Load pre-trained ResNet101 model
resnet = torchvision.models.resnet101(pretrained=True)
num_ftrs = resnet.fc.in_features
resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Adjust input channels to 3
resnet.fc = nn.Linear(num_ftrs, 10)  # Change output to match FashionMNIST classes

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
resnet = resnet.to(device)

criterion = nn.CrossEntropyLoss()

optimizers = {
    "Adam": optim.Adam(resnet.parameters()),
    "Adagrad": optim.Adagrad(resnet.parameters()),
    "RMSprop": optim.RMSprop(resnet.parameters())
}

# Training loop
num_epochs = 1  # Reduce number of epochs
for optimizer_name, optimizer in optimizers.items():
    print(f"Training with {optimizer_name} optimizer...")
    train_loss_history = []
    train_acc_history = []

    resnet.train()  # Set model to train mode

    for epoch in range(num_epochs):
        running_loss = 0.0
        correct = 0
        total = 0
        iteration_count = 0

        for inputs, labels in trainloader:
            if iteration_count > 4:
              break

            iteration_count = iteration_count + 1

            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = resnet(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        epoch_loss = running_loss / len(trainloader)
        epoch_acc = correct / total
        train_loss_history.append(epoch_loss)
        train_acc_history.append(epoch_acc)
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}")

    plt.plot(train_loss_history, label=f"{optimizer_name} Loss")
    plt.plot(train_acc_history, label=f"{optimizer_name} Accuracy")

plt.xlabel("Epoch")
plt.ylabel("Value")
plt.title("Training Loss and Accuracy")
plt.legend()
plt.show()

# Testing
resnet.eval()  # Set model to evaluation mode
top5_correct = 0
total = 0


with torch.no_grad():

  iteration_count = 0

  for inputs, labels in testloader:

    if iteration_count > 4 :
      break

    iteration_count = iteration_count + 1

    inputs, labels = inputs.to(device), labels.to(device)
    outputs = resnet(inputs)
    _, predicted = torch.topk(outputs, 5, dim=1)
    total += labels.size(0)
    for i in range(len(labels)):
        if labels[i] in predicted[i]:
            top5_correct += 1

top5_accuracy = top5_correct / total
print(f"Final Top-5 Test Accuracy: {top5_accuracy:.4f}")

